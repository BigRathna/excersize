{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Pose estimation\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reference video and extract the target keypoints (replace with the appropriate reference video)\n",
    "reference_video = cv2.VideoCapture('reference video.mp4')\n",
    "target_keypoints = []  # Store the target keypoints for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate similarity score between two sets of keypoints\n",
    "def calculate_similarity_score(keypoints1, keypoints2):\n",
    "    # Calculate the Euclidean distance between corresponding keypoints\n",
    "    distances = np.linalg.norm(keypoints1 - keypoints2, axis=1)\n",
    "    \n",
    "    # Calculate the average distance as the similarity score\n",
    "    score = np.mean(distances)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1 Score: -0.05\n",
      "Repetition 2 Score: -0.01\n",
      "Repetition 3 Score: -0.0\n",
      "Repetition 4 Score: 0.0\n",
      "Repetition 5 Score: -0.0\n",
      "Repetition 6 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Parameters for repetition detection\n",
    "repetition_threshold = 0.5\n",
    "repetition_count = 0\n",
    "previous_score = 0\n",
    "repetition_started = False\n",
    "\n",
    "while True:\n",
    "    # Read the frame from the video capture\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to RGB and perform pose estimation\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # Process the pose estimation results to extract body keypoints\n",
    "    if results.pose_landmarks is not None:\n",
    "        # Extract keypoints for the body\n",
    "        keypoints = np.array([[lmk.x, lmk.y, lmk.z] for lmk in results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER.value:mp_pose.PoseLandmark.RIGHT_HIP.value+1]])\n",
    "        \n",
    "        # Store the keypoints as the user's pose\n",
    "        user_pose = keypoints\n",
    "\n",
    "    # Extract the target keypoints from the reference video\n",
    "    ret_ref, frame_ref = reference_video.read()\n",
    "    if not ret_ref:\n",
    "        # Restart the reference video if it has ended\n",
    "        reference_video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        continue\n",
    "\n",
    "    # Convert the frame to RGB and perform pose estimation on the reference video frame\n",
    "    rgb_frame_ref = cv2.cvtColor(frame_ref, cv2.COLOR_BGR2RGB)\n",
    "    results_ref = pose.process(rgb_frame_ref)\n",
    "\n",
    "    # Process the pose estimation results to extract body keypoints from the reference video\n",
    "    if results_ref.pose_landmarks is not None:\n",
    "        # Extract keypoints for the body from the reference video\n",
    "        keypoints_ref = np.array([[lmk.x, lmk.y, lmk.z] for lmk in results_ref.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER.value:mp_pose.PoseLandmark.RIGHT_HIP.value+1]])\n",
    "        \n",
    "        # Store the keypoints as the reference pose\n",
    "        target_keypoints = keypoints_ref\n",
    "\n",
    "    # Calculate the similarity score between user's pose and reference pose\n",
    "    if user_pose.shape[0] != 0 and target_keypoints.shape[0] != 0:\n",
    "        similarity_score = calculate_similarity_score(user_pose, target_keypoints)\n",
    "        similarity_score = round(similarity_score, 2)\n",
    "        \n",
    "        if similarity_score < repetition_threshold and not repetition_started:\n",
    "            # Start of a repetition\n",
    "            repetition_started = True\n",
    "            repetition_count += 1\n",
    "\n",
    "        if similarity_score >= repetition_threshold and repetition_started:\n",
    "            # End of a repetition\n",
    "            repetition_started = False\n",
    "            \n",
    "            if repetition_count > 1:\n",
    "                # Calculate score for the completed repetition\n",
    "                repetition_score = round((similarity_score - previous_score) / (repetition_count - 1), 2)\n",
    "                print(f\"Repetition {repetition_count - 1} Score: {repetition_score}\")\n",
    "\n",
    "            previous_score = similarity_score\n",
    "\n",
    "        # Display the similarity score on the frame\n",
    "        cv2.putText(frame, f\"Similarity Score: {similarity_score}\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the frame with keypoints and similarity score\n",
    "    cv2.imshow(\"Exercise Grader\", frame)\n",
    "\n",
    "    # Check for user input to exit the application\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close any open windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
